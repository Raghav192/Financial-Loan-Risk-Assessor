{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53e1c35e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Work\\Projects\\FinancialRiskAssessor\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model Training & Optimization Script Initialized ---\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import shap\n",
    "import optuna\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer\n",
    "from sklearn.metrics import roc_auc_score, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "print(\"--- Model Training & Optimization Script Initialized ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d24f340b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading a sample of 300000 rows...\n",
      "Sample loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Load a Large, Representative Sample\n",
    "try:\n",
    "    file_path = '../data/lending_club_accepted.csv'\n",
    "    n_rows_to_sample = 300000  # Increased sample size for accuracy\n",
    "    print(f\"Loading a sample of {n_rows_to_sample} rows...\")\n",
    "    df = pd.read_csv(file_path, nrows=n_rows_to_sample, low_memory=False)\n",
    "    print(\"Sample loaded successfully!\")\n",
    "except FileNotFoundError:\n",
    "    print(\"ERROR: Data file not found. Please place 'lending_club_accepted.csv' in the 'data' folder.\")\n",
    "    df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0136ead4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RAGHAV\\AppData\\Local\\Temp\\ipykernel_13304\\986780280.py:10: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['earliest_cr_line'] = pd.to_datetime(df['earliest_cr_line'], errors='coerce')\n",
      "C:\\Users\\RAGHAV\\AppData\\Local\\Temp\\ipykernel_13304\\986780280.py:11: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['issue_d'] = pd.to_datetime(df['issue_d'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing Advanced Feature Engineering...\n",
      "Advanced Feature Engineering complete.\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Advanced Preprocessing & Feature Engineering\n",
    "if df is not None:\n",
    "    df = df[df['loan_status'].isin(['Fully Paid', 'Charged Off', 'Default'])]\n",
    "    df['is_default'] = df['loan_status'].apply(lambda x: 1 if x in ['Charged Off', 'Default'] else 0)\n",
    "    \n",
    "    df['emp_length'].replace({'< 1 year': '0 years', '10+ years': '10 years'}, inplace=True)\n",
    "    df['emp_length'] = df['emp_length'].str.replace(r'\\D', '', regex=True).astype(float)\n",
    "    df['emp_length'].fillna(df['emp_length'].median(), inplace=True)\n",
    "    \n",
    "    df['earliest_cr_line'] = pd.to_datetime(df['earliest_cr_line'], errors='coerce')\n",
    "    df['issue_d'] = pd.to_datetime(df['issue_d'], errors='coerce')\n",
    "    df['credit_history_length'] = (df['issue_d'] - df['earliest_cr_line']).dt.days / 365.25\n",
    "    df.drop(columns=['earliest_cr_line', 'issue_d'], inplace=True)\n",
    "    \n",
    "    # --- Feature Engineering ---\n",
    "    print(\"Performing Advanced Feature Engineering...\")\n",
    "    df['loan_to_income_ratio'] = df['loan_amnt'] / (df['annual_inc'] + 1) # Add 1 to avoid division by zero\n",
    "    df['interest_to_income_ratio'] = (df['installment'] * 12) / (df['annual_inc'] + 1)\n",
    "    df['revol_util_to_open_acc'] = df['revol_util'] / (df['open_acc'] + 1)\n",
    "    print(\"Advanced Feature Engineering complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cdb707f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features selected.\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Feature Selection\n",
    "if df is not None:\n",
    "    features_to_use = [\n",
    "        'loan_amnt', 'term', 'int_rate', 'installment', 'grade', 'sub_grade', 'emp_length',\n",
    "        'home_ownership', 'annual_inc', 'verification_status', 'purpose', 'dti', 'open_acc',\n",
    "        'pub_rec', 'revol_bal', 'revol_util', 'total_acc', 'initial_list_status',\n",
    "        'application_type', 'mort_acc', 'pub_rec_bankruptcies', 'credit_history_length',\n",
    "        'loan_to_income_ratio', 'interest_to_income_ratio', 'revol_util_to_open_acc' # New features\n",
    "    ]\n",
    "    target = 'is_default'\n",
    "    df_model = df[features_to_use + [target]].copy().dropna()\n",
    "    X = df_model[features_to_use]\n",
    "    y = df_model[target]\n",
    "    print(\"Features selected.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e87d487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing pipeline created and data split.\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Create Preprocessing Pipeline & Split Data\n",
    "if df is not None:\n",
    "    numeric_features = X.select_dtypes(include=np.number).columns.tolist()\n",
    "    categorical_features = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', StandardScaler(), numeric_features),\n",
    "            ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features)\n",
    "        ], remainder='passthrough')\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "    print(\"Preprocessing pipeline created and data split.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b77a27b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Model Bake-Off: Comparing Performance with Stratified 3-Fold CV ---\n",
      "RandomForest - Mean CV ROC AUC: 0.7215 (Std: 0.0012)\n",
      "LightGBM - Mean CV ROC AUC: 0.7372 (Std: 0.0018)\n",
      "XGBoost - Mean CV ROC AUC: 0.7287 (Std: 0.0015)\n",
      "\n",
      " Proceeding to optimize champion candidate: XGBoost\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: High-Efficiency Model Bake-Off with StratifiedKFold\n",
    "if df is not None:\n",
    "    print(\"\\n--- Model Bake-Off: Comparing Performance with Stratified 3-Fold CV ---\")\n",
    "    \n",
    "    models = {\n",
    "        'RandomForest': RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42, n_jobs=-1),\n",
    "        'LightGBM': lgb.LGBMClassifier(class_weight='balanced', random_state=42),\n",
    "        'XGBoost': xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "    }\n",
    "    \n",
    "    # Use StratifiedKFold for robust evaluation on imbalanced data\n",
    "    cv_strategy = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('classifier', model)])\n",
    "        \n",
    "        # This is inherently parallel if n_jobs is set in the model\n",
    "        scores = cross_val_score(pipeline, X_train, y_train, cv=cv_strategy, scoring='roc_auc', n_jobs=-1)\n",
    "        print(f\"{name} - Mean CV ROC AUC: {np.mean(scores):.4f} (Std: {np.std(scores):.4f})\")\n",
    "    \n",
    "    # For this example, we will proceed to optimize XGBoost as it's typically the top performer.\n",
    "    best_model_name = 'XGBoost'\n",
    "    print(f\"\\n Proceeding to optimize champion candidate: {best_model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a201da9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-07 00:33:07,841] A new study created in memory with name: no-name-c476b5ad-64cb-49b0-b473-32a0aec3e4e5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Advanced Hyperparameter Optimization for XGBoost ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Work\\Projects\\FinancialRiskAssessor\\venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:33:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-07 00:33:22,288] Trial 0 finished with value: 0.728433310231672 and parameters: {'n_estimators': 500, 'learning_rate': 0.07482006318810987, 'max_depth': 9, 'subsample': 0.8067432385325863, 'colsample_bytree': 0.8525996795861523, 'gamma': 1.2980904736099084e-07, 'min_child_weight': 12, 'scale_pos_weight': 2.865668784817782}. Best is trial 0 with value: 0.728433310231672.\n",
      "d:\\Work\\Projects\\FinancialRiskAssessor\\venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:33:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-07 00:33:46,016] Trial 1 finished with value: 0.7287852583309601 and parameters: {'n_estimators': 1200, 'learning_rate': 0.09247810742054613, 'max_depth': 5, 'subsample': 0.8441374931913039, 'colsample_bytree': 0.9496099122822859, 'gamma': 2.0178948337706793e-08, 'min_child_weight': 1, 'scale_pos_weight': 5.6483080042070934}. Best is trial 1 with value: 0.7287852583309601.\n",
      "d:\\Work\\Projects\\FinancialRiskAssessor\\venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:33:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-07 00:34:22,702] Trial 2 finished with value: 0.7094602002857089 and parameters: {'n_estimators': 800, 'learning_rate': 0.08000589862994044, 'max_depth': 12, 'subsample': 0.8009424895373496, 'colsample_bytree': 0.782306271422831, 'gamma': 2.4450879922988457e-06, 'min_child_weight': 12, 'scale_pos_weight': 7.438004330462056}. Best is trial 1 with value: 0.7287852583309601.\n",
      "d:\\Work\\Projects\\FinancialRiskAssessor\\venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:34:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-07 00:34:44,801] Trial 3 finished with value: 0.7401944716824316 and parameters: {'n_estimators': 800, 'learning_rate': 0.010029040184171077, 'max_depth': 7, 'subsample': 0.976143663002691, 'colsample_bytree': 0.7688958105300443, 'gamma': 0.03574599061982479, 'min_child_weight': 1, 'scale_pos_weight': 6.942124832390897}. Best is trial 3 with value: 0.7401944716824316.\n",
      "d:\\Work\\Projects\\FinancialRiskAssessor\\venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:34:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-07 00:35:31,158] Trial 4 finished with value: 0.7387636282975181 and parameters: {'n_estimators': 1900, 'learning_rate': 0.010093030838648143, 'max_depth': 7, 'subsample': 0.8653829011180252, 'colsample_bytree': 0.9222621692958515, 'gamma': 0.9859843888253229, 'min_child_weight': 15, 'scale_pos_weight': 13.846640795145053}. Best is trial 3 with value: 0.7401944716824316.\n",
      "d:\\Work\\Projects\\FinancialRiskAssessor\\venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:35:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-07 00:36:21,578] Trial 5 finished with value: 0.7327666712041586 and parameters: {'n_estimators': 1500, 'learning_rate': 0.014235156933489, 'max_depth': 9, 'subsample': 0.85051864650863, 'colsample_bytree': 0.8620069423059107, 'gamma': 0.005597739742266719, 'min_child_weight': 7, 'scale_pos_weight': 9.252289213297693}. Best is trial 3 with value: 0.7401944716824316.\n",
      "d:\\Work\\Projects\\FinancialRiskAssessor\\venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:36:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-07 00:36:46,872] Trial 6 finished with value: 0.7371633918235762 and parameters: {'n_estimators': 900, 'learning_rate': 0.018824000877537325, 'max_depth': 12, 'subsample': 0.9248526124568595, 'colsample_bytree': 0.7525094512487097, 'gamma': 4.98129483321813, 'min_child_weight': 6, 'scale_pos_weight': 3.018711984954055}. Best is trial 3 with value: 0.7401944716824316.\n",
      "d:\\Work\\Projects\\FinancialRiskAssessor\\venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:36:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-07 00:37:17,649] Trial 7 finished with value: 0.7325985548699598 and parameters: {'n_estimators': 1000, 'learning_rate': 0.03042633095171034, 'max_depth': 9, 'subsample': 0.8461626485188227, 'colsample_bytree': 0.9044675758811975, 'gamma': 0.018166918931438517, 'min_child_weight': 15, 'scale_pos_weight': 5.297951545842988}. Best is trial 3 with value: 0.7401944716824316.\n",
      "d:\\Work\\Projects\\FinancialRiskAssessor\\venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:37:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-07 00:38:36,888] Trial 8 finished with value: 0.7267269048187868 and parameters: {'n_estimators': 2000, 'learning_rate': 0.016472778935098513, 'max_depth': 11, 'subsample': 0.8415899831980037, 'colsample_bytree': 0.9327784961778557, 'gamma': 2.850905174307847e-06, 'min_child_weight': 12, 'scale_pos_weight': 6.701701886694289}. Best is trial 3 with value: 0.7401944716824316.\n",
      "d:\\Work\\Projects\\FinancialRiskAssessor\\venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:38:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-07 00:39:33,658] Trial 9 finished with value: 0.7354093058418385 and parameters: {'n_estimators': 1500, 'learning_rate': 0.011765940248944038, 'max_depth': 10, 'subsample': 0.7841453722732186, 'colsample_bytree': 0.9494479620410675, 'gamma': 4.303629002086898e-05, 'min_child_weight': 9, 'scale_pos_weight': 4.057191508867604}. Best is trial 3 with value: 0.7401944716824316.\n",
      "d:\\Work\\Projects\\FinancialRiskAssessor\\venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:39:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-07 00:39:45,800] Trial 10 finished with value: 0.7383695076312319 and parameters: {'n_estimators': 500, 'learning_rate': 0.041759518203050204, 'max_depth': 6, 'subsample': 0.9844270114153919, 'colsample_bytree': 0.7214892359453293, 'gamma': 0.02111181637821373, 'min_child_weight': 1, 'scale_pos_weight': 10.366818764011747}. Best is trial 3 with value: 0.7401944716824316.\n",
      "d:\\Work\\Projects\\FinancialRiskAssessor\\venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:39:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-07 00:40:33,428] Trial 11 finished with value: 0.7371075384815724 and parameters: {'n_estimators': 1900, 'learning_rate': 0.011172061276294219, 'max_depth': 7, 'subsample': 0.9360070470802836, 'colsample_bytree': 0.7894943326198852, 'gamma': 5.042154225563204, 'min_child_weight': 4, 'scale_pos_weight': 14.844275462247674}. Best is trial 3 with value: 0.7401944716824316.\n",
      "d:\\Work\\Projects\\FinancialRiskAssessor\\venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:40:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-07 00:41:16,540] Trial 12 finished with value: 0.7351590839271978 and parameters: {'n_estimators': 1700, 'learning_rate': 0.0235758747736736, 'max_depth': 7, 'subsample': 0.7064326938692371, 'colsample_bytree': 0.8121929711153633, 'gamma': 0.31713884453290575, 'min_child_weight': 15, 'scale_pos_weight': 12.387558529243952}. Best is trial 3 with value: 0.7401944716824316.\n",
      "d:\\Work\\Projects\\FinancialRiskAssessor\\venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:41:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-07 00:41:52,243] Trial 13 finished with value: 0.7380075988613902 and parameters: {'n_estimators': 1300, 'learning_rate': 0.0100013168780828, 'max_depth': 7, 'subsample': 0.9970856018159489, 'colsample_bytree': 0.9939966147029536, 'gamma': 0.0009218701166832237, 'min_child_weight': 4, 'scale_pos_weight': 11.859593988647866}. Best is trial 3 with value: 0.7401944716824316.\n",
      "d:\\Work\\Projects\\FinancialRiskAssessor\\venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:41:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-07 00:42:11,590] Trial 14 finished with value: 0.7316885327179882 and parameters: {'n_estimators': 700, 'learning_rate': 0.04294034981191717, 'max_depth': 8, 'subsample': 0.9171461007615913, 'colsample_bytree': 0.7009923232965377, 'gamma': 0.22676012408298535, 'min_child_weight': 10, 'scale_pos_weight': 14.870735657133086}. Best is trial 3 with value: 0.7401944716824316.\n",
      "d:\\Work\\Projects\\FinancialRiskAssessor\\venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:42:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-07 00:42:33,674] Trial 15 finished with value: 0.741902190202959 and parameters: {'n_estimators': 1100, 'learning_rate': 0.024658717233604344, 'max_depth': 5, 'subsample': 0.8898989054237338, 'colsample_bytree': 0.8873966756363493, 'gamma': 0.23882038056480054, 'min_child_weight': 4, 'scale_pos_weight': 1.4190482446292698}. Best is trial 15 with value: 0.741902190202959.\n",
      "d:\\Work\\Projects\\FinancialRiskAssessor\\venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:42:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-07 00:42:58,232] Trial 16 finished with value: 0.741649163613774 and parameters: {'n_estimators': 1100, 'learning_rate': 0.02328283949640864, 'max_depth': 5, 'subsample': 0.9570539723044181, 'colsample_bytree': 0.8825403314948523, 'gamma': 0.00015006904307352632, 'min_child_weight': 3, 'scale_pos_weight': 1.0721170536472746}. Best is trial 15 with value: 0.741902190202959.\n",
      "d:\\Work\\Projects\\FinancialRiskAssessor\\venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:42:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-07 00:43:23,250] Trial 17 finished with value: 0.7418657437546887 and parameters: {'n_estimators': 1100, 'learning_rate': 0.02391479791255564, 'max_depth': 5, 'subsample': 0.8944122284495355, 'colsample_bytree': 0.8817736714808893, 'gamma': 7.268664045422394e-05, 'min_child_weight': 4, 'scale_pos_weight': 1.0968732961908767}. Best is trial 15 with value: 0.741902190202959.\n",
      "d:\\Work\\Projects\\FinancialRiskAssessor\\venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:43:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-07 00:43:46,746] Trial 18 finished with value: 0.7403392825591844 and parameters: {'n_estimators': 1200, 'learning_rate': 0.03752180873815902, 'max_depth': 5, 'subsample': 0.8844376794148543, 'colsample_bytree': 0.8260407313568453, 'gamma': 0.0014998520743108605, 'min_child_weight': 6, 'scale_pos_weight': 2.003979583954082}. Best is trial 15 with value: 0.741902190202959.\n",
      "d:\\Work\\Projects\\FinancialRiskAssessor\\venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:43:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-07 00:44:18,902] Trial 19 finished with value: 0.738074700644781 and parameters: {'n_estimators': 1400, 'learning_rate': 0.027642400625838934, 'max_depth': 6, 'subsample': 0.8910975923886431, 'colsample_bytree': 0.9851120172014394, 'gamma': 1.6615369324085955e-05, 'min_child_weight': 3, 'scale_pos_weight': 4.272978542758624}. Best is trial 15 with value: 0.741902190202959.\n",
      "d:\\Work\\Projects\\FinancialRiskAssessor\\venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:44:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-07 00:44:40,674] Trial 20 finished with value: 0.7377340020884802 and parameters: {'n_estimators': 1000, 'learning_rate': 0.0492994434361961, 'max_depth': 6, 'subsample': 0.7557092641396459, 'colsample_bytree': 0.8971681629467431, 'gamma': 1.0046545994874419e-06, 'min_child_weight': 5, 'scale_pos_weight': 1.254295733311236}. Best is trial 15 with value: 0.741902190202959.\n",
      "d:\\Work\\Projects\\FinancialRiskAssessor\\venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:44:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-07 00:45:02,631] Trial 21 finished with value: 0.7417082843024778 and parameters: {'n_estimators': 1100, 'learning_rate': 0.022534013959225684, 'max_depth': 5, 'subsample': 0.9532923939307627, 'colsample_bytree': 0.8790066592288698, 'gamma': 0.00010756772720113321, 'min_child_weight': 3, 'scale_pos_weight': 1.0441466644036577}. Best is trial 15 with value: 0.741902190202959.\n",
      "d:\\Work\\Projects\\FinancialRiskAssessor\\venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:45:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-07 00:45:24,804] Trial 22 finished with value: 0.7416347866273337 and parameters: {'n_estimators': 1100, 'learning_rate': 0.02127353686927945, 'max_depth': 5, 'subsample': 0.9012533313356357, 'colsample_bytree': 0.8727945930227203, 'gamma': 0.00018326831675375798, 'min_child_weight': 3, 'scale_pos_weight': 2.7401961226001497}. Best is trial 15 with value: 0.741902190202959.\n",
      "d:\\Work\\Projects\\FinancialRiskAssessor\\venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:45:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-07 00:45:52,523] Trial 23 finished with value: 0.7387066149703237 and parameters: {'n_estimators': 1300, 'learning_rate': 0.02711243396139779, 'max_depth': 6, 'subsample': 0.9493196360157472, 'colsample_bytree': 0.8197312279811713, 'gamma': 1.6083902084607962e-05, 'min_child_weight': 2, 'scale_pos_weight': 3.8231385319193243}. Best is trial 15 with value: 0.741902190202959.\n",
      "d:\\Work\\Projects\\FinancialRiskAssessor\\venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:45:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-07 00:46:13,606] Trial 24 finished with value: 0.7421454500032557 and parameters: {'n_estimators': 1000, 'learning_rate': 0.016311976803135272, 'max_depth': 5, 'subsample': 0.9051643549876769, 'colsample_bytree': 0.8357097839119043, 'gamma': 0.0007502146362241052, 'min_child_weight': 5, 'scale_pos_weight': 1.1331208163138011}. Best is trial 24 with value: 0.7421454500032557.\n",
      "d:\\Work\\Projects\\FinancialRiskAssessor\\venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:46:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-07 00:46:34,202] Trial 25 finished with value: 0.7418782281916918 and parameters: {'n_estimators': 700, 'learning_rate': 0.014848044428106737, 'max_depth': 6, 'subsample': 0.8713165350331769, 'colsample_bytree': 0.836132131099068, 'gamma': 0.0013210920628905596, 'min_child_weight': 8, 'scale_pos_weight': 2.377047634616699}. Best is trial 24 with value: 0.7421454500032557.\n",
      "d:\\Work\\Projects\\FinancialRiskAssessor\\venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:46:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-07 00:46:51,800] Trial 26 finished with value: 0.7413461596189634 and parameters: {'n_estimators': 700, 'learning_rate': 0.01453664566510259, 'max_depth': 6, 'subsample': 0.8730230683736482, 'colsample_bytree': 0.8340376361371117, 'gamma': 0.002211252641629048, 'min_child_weight': 7, 'scale_pos_weight': 5.135723687720134}. Best is trial 24 with value: 0.7421454500032557.\n",
      "d:\\Work\\Projects\\FinancialRiskAssessor\\venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:46:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-07 00:47:10,743] Trial 27 finished with value: 0.7405365219023876 and parameters: {'n_estimators': 600, 'learning_rate': 0.017325168043302166, 'max_depth': 8, 'subsample': 0.8233191094472557, 'colsample_bytree': 0.8368986387323256, 'gamma': 0.11426981798809636, 'min_child_weight': 9, 'scale_pos_weight': 2.3856253600623036}. Best is trial 24 with value: 0.7421454500032557.\n",
      "d:\\Work\\Projects\\FinancialRiskAssessor\\venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:47:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-07 00:47:32,240] Trial 28 finished with value: 0.7417209989739584 and parameters: {'n_estimators': 900, 'learning_rate': 0.013873573454903271, 'max_depth': 6, 'subsample': 0.9173202920982367, 'colsample_bytree': 0.7976145782822829, 'gamma': 0.0006661161594262618, 'min_child_weight': 8, 'scale_pos_weight': 3.8047330336368956}. Best is trial 24 with value: 0.7421454500032557.\n",
      "d:\\Work\\Projects\\FinancialRiskAssessor\\venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:47:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-07 00:47:49,278] Trial 29 finished with value: 0.7340705011679113 and parameters: {'n_estimators': 500, 'learning_rate': 0.05930136807984222, 'max_depth': 8, 'subsample': 0.8120674510495003, 'colsample_bytree': 0.8546113401535248, 'gamma': 0.004788396255677633, 'min_child_weight': 6, 'scale_pos_weight': 2.332573198504466}. Best is trial 24 with value: 0.7421454500032557.\n",
      "d:\\Work\\Projects\\FinancialRiskAssessor\\venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:47:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-07 00:48:08,432] Trial 30 finished with value: 0.7416632266441086 and parameters: {'n_estimators': 900, 'learning_rate': 0.019195727585600276, 'max_depth': 5, 'subsample': 0.8735102496754747, 'colsample_bytree': 0.8528190040922603, 'gamma': 1.1564037385919916, 'min_child_weight': 11, 'scale_pos_weight': 8.799646185806491}. Best is trial 24 with value: 0.7421454500032557.\n",
      "d:\\Work\\Projects\\FinancialRiskAssessor\\venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:48:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-07 00:48:28,478] Trial 31 finished with value: 0.7415600915125866 and parameters: {'n_estimators': 1000, 'learning_rate': 0.0347186051285672, 'max_depth': 5, 'subsample': 0.8990342693988963, 'colsample_bytree': 0.8991005428954549, 'gamma': 3.652439693901493e-05, 'min_child_weight': 5, 'scale_pos_weight': 1.6912834373390782}. Best is trial 24 with value: 0.7421454500032557.\n",
      "d:\\Work\\Projects\\FinancialRiskAssessor\\venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:48:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-07 00:48:55,630] Trial 32 finished with value: 0.7416902015323901 and parameters: {'n_estimators': 1200, 'learning_rate': 0.016284710041260968, 'max_depth': 5, 'subsample': 0.9042410858124279, 'colsample_bytree': 0.8447701539687182, 'gamma': 0.0004148200369777563, 'min_child_weight': 4, 'scale_pos_weight': 2.617166199639123}. Best is trial 24 with value: 0.7421454500032557.\n",
      "d:\\Work\\Projects\\FinancialRiskAssessor\\venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:48:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-07 00:49:14,143] Trial 33 finished with value: 0.7409150714474315 and parameters: {'n_estimators': 800, 'learning_rate': 0.02715702208453463, 'max_depth': 6, 'subsample': 0.8612980105085485, 'colsample_bytree': 0.912752948457835, 'gamma': 4.0560707297921926e-08, 'min_child_weight': 5, 'scale_pos_weight': 3.23910218700051}. Best is trial 24 with value: 0.7421454500032557.\n",
      "d:\\Work\\Projects\\FinancialRiskAssessor\\venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-07 00:49:30,182] Trial 34 finished with value: 0.7414796284182976 and parameters: {'n_estimators': 700, 'learning_rate': 0.012946935443238635, 'max_depth': 5, 'subsample': 0.9347787414365234, 'colsample_bytree': 0.8109435839569198, 'gamma': 1.1672798713475234e-06, 'min_child_weight': 7, 'scale_pos_weight': 1.753760567648761}. Best is trial 24 with value: 0.7421454500032557.\n",
      "d:\\Work\\Projects\\FinancialRiskAssessor\\venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-07 00:50:00,974] Trial 35 finished with value: 0.7394514840930945 and parameters: {'n_estimators': 1400, 'learning_rate': 0.019106626048419912, 'max_depth': 6, 'subsample': 0.8290489433609904, 'colsample_bytree': 0.8844273128809084, 'gamma': 6.489447843293205e-06, 'min_child_weight': 2, 'scale_pos_weight': 6.001106456988117}. Best is trial 24 with value: 0.7421454500032557.\n",
      "d:\\Work\\Projects\\FinancialRiskAssessor\\venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-07 00:50:22,466] Trial 36 finished with value: 0.7408665470526952 and parameters: {'n_estimators': 1100, 'learning_rate': 0.031117689479683755, 'max_depth': 5, 'subsample': 0.8840060479164167, 'colsample_bytree': 0.7686480079110958, 'gamma': 0.05348276881584589, 'min_child_weight': 8, 'scale_pos_weight': 4.6170955620427225}. Best is trial 24 with value: 0.7421454500032557.\n",
      "d:\\Work\\Projects\\FinancialRiskAssessor\\venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-07 00:50:44,151] Trial 37 finished with value: 0.7412729395471129 and parameters: {'n_estimators': 800, 'learning_rate': 0.01546554276728102, 'max_depth': 7, 'subsample': 0.910927598345898, 'colsample_bytree': 0.8628712831802089, 'gamma': 0.004338372848852375, 'min_child_weight': 5, 'scale_pos_weight': 1.7597667007145468}. Best is trial 24 with value: 0.7421454500032557.\n",
      "d:\\Work\\Projects\\FinancialRiskAssessor\\venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-07 00:51:01,685] Trial 38 finished with value: 0.7342158165776337 and parameters: {'n_estimators': 900, 'learning_rate': 0.0968318516652034, 'max_depth': 5, 'subsample': 0.8585438923527473, 'colsample_bytree': 0.9423913410336153, 'gamma': 0.012735690497628297, 'min_child_weight': 2, 'scale_pos_weight': 3.102894144527238}. Best is trial 24 with value: 0.7421454500032557.\n",
      "d:\\Work\\Projects\\FinancialRiskAssessor\\venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-07 00:51:19,168] Trial 39 finished with value: 0.7418938004145343 and parameters: {'n_estimators': 600, 'learning_rate': 0.01988765086109733, 'max_depth': 6, 'subsample': 0.7929837127199967, 'colsample_bytree': 0.9266274579638327, 'gamma': 3.9311963545774726e-07, 'min_child_weight': 13, 'scale_pos_weight': 3.467427701746222}. Best is trial 24 with value: 0.7421454500032557.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Finished.\n",
      "Best trial ROC AUC: 0.7421\n",
      "Best hyperparameters found: {'n_estimators': 1000, 'learning_rate': 0.016311976803135272, 'max_depth': 5, 'subsample': 0.9051643549876769, 'colsample_bytree': 0.8357097839119043, 'gamma': 0.0007502146362241052, 'min_child_weight': 5, 'scale_pos_weight': 1.1331208163138011}\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Advanced Hyperparameter Tuning of the Champion Model\n",
    "if df is not None:\n",
    "    print(f\"\\n--- Starting Advanced Hyperparameter Optimization for {best_model_name} ---\")\n",
    "    \n",
    "    def objective(trial):\n",
    "        params = {\n",
    "            'objective': 'binary:logistic', 'eval_metric': 'auc', 'use_label_encoder': False, 'random_state': 42,\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 500, 2000, step=100),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1, log=True),\n",
    "            'max_depth': trial.suggest_int('max_depth', 5, 12),\n",
    "            'subsample': trial.suggest_float('subsample', 0.7, 1.0),\n",
    "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.7, 1.0),\n",
    "            'gamma': trial.suggest_float('gamma', 1e-8, 10.0, log=True),\n",
    "            'min_child_weight': trial.suggest_int('min_child_weight', 1, 15),\n",
    "            'scale_pos_weight': trial.suggest_float('scale_pos_weight', 1, 15)\n",
    "        }\n",
    "        model = xgb.XGBClassifier(**params)\n",
    "        pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('classifier', model)])\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        return roc_auc_score(y_test, pipeline.predict_proba(X_test)[:, 1])\n",
    "\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective, n_trials=40) # A more extensive search\n",
    "    print(\"Optimization Finished.\")\n",
    "    print(f\"Best trial ROC AUC: {study.best_value:.4f}\")\n",
    "    print(\"Best hyperparameters found:\", study.best_params)\n",
    "    \n",
    "    final_params = study.best_params\n",
    "    final_model = xgb.XGBClassifier(**final_params, random_state=42, use_label_encoder=False, eval_metric='logloss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4d14a29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Retraining and Saving Final Model (XGBoost) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Work\\Projects\\FinancialRiskAssessor\\venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Model Performance on Unseen Test Set ---\n",
      "Final Test Set ROC AUC: 0.7421\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.96      0.89     42439\n",
      "           1       0.56      0.19      0.28     10695\n",
      "\n",
      "    accuracy                           0.81     53134\n",
      "   macro avg       0.69      0.58      0.59     53134\n",
      "weighted avg       0.77      0.81      0.77     53134\n",
      "\n",
      "✅ Final model pipeline saved.\n",
      "✅ SHAP explainer and feature names for  model saved.\n",
      "\n",
      "--- SCRIPT COMPLETE ---\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Retrain and Save the Final Champion Model and Artifacts\n",
    "if df is not None:\n",
    "    print(f\"\\n--- Retraining and Saving Final Model ({best_model_name}) ---\")\n",
    "    \n",
    "    final_pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('classifier', final_model)])\n",
    "    final_pipeline.fit(X_train, y_train)\n",
    "\n",
    "    print(\"\\n--- Final Model Performance on Unseen Test Set ---\")\n",
    "    y_pred_proba = final_pipeline.predict_proba(X_test)[:, 1]\n",
    "    y_pred = final_pipeline.predict(X_test)\n",
    "    final_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    print(f\"Final Test Set ROC AUC: {final_auc:.4f}\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    joblib.dump(final_pipeline, '../models/best_model.joblib')\n",
    "    print(\"✅ Final model pipeline saved.\")\n",
    "    \n",
    "    X_train_processed = final_pipeline.named_steps['preprocessor'].transform(X_train)\n",
    "    model_for_shap = final_pipeline.named_steps['classifier']\n",
    "    explainer = shap.TreeExplainer(model_for_shap, X_train_processed, feature_perturbation=\"interventional\")\n",
    "    \n",
    "    joblib.dump(explainer, '../models/shap_explainer.joblib')\n",
    "    processed_feature_names = final_pipeline.named_steps['preprocessor'].get_feature_names_out()\n",
    "    joblib.dump(processed_feature_names, '../models/processed_feature_names.joblib')\n",
    "    print(\"✅ SHAP explainer and feature names for  model saved.\")\n",
    "    print(\"\\n--- SCRIPT COMPLETE ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
